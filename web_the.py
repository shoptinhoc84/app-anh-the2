import streamlit as st
from PIL import Image, ImageEnhance
import cv2
import numpy as np
from rembg import remove, new_session
import io

# --- 1. C·∫§U H√åNH & CACHE ---
st.set_page_config(page_title="Studio ·∫¢nh Th·∫ª Online", layout="wide")

# [QUAN TR·ªåNG] D√πng model 'u2netp' (b·∫£n nh·∫π) ƒë·ªÉ tr√°nh b·ªã l·ªói h·∫øt RAM tr√™n web mi·ªÖn ph√≠
@st.cache_resource
def get_rembg_session():
    return new_session("u2netp")

st.title("üì∏ Studio ·∫¢nh Th·∫ª - Web Version")
st.markdown("---")

# --- 2. C√ÅC H√ÄM X·ª¨ L√ù ·∫¢NH ---

def process_input_image(uploaded_file, target_ratio=4/6):
    """
    X·ª≠ l√Ω t√°ch n·ªÅn v√† crop m·∫∑t theo t·ª∑ l·ªá (3:4 ho·∫∑c 4:6)
    target_ratio: 0.75 (3x4) ho·∫∑c 0.666 (4x6)
    """
    try:
        image = Image.open(uploaded_file)
        
        # 1. T√°ch n·ªÅn
        with st.spinner('ƒêang t√°ch n·ªÅn v√† t√¨m khu√¥n m·∫∑t...'):
            session = get_rembg_session()
            no_bg = remove(image, session=session)

        # 2. T√¨m m·∫∑t (OpenCV)
        cv_img = cv2.cvtColor(np.array(no_bg.convert("RGB")), cv2.COLOR_RGB2BGR)
        gray = cv2.cvtColor(cv_img, cv2.COLOR_BGR2GRAY)
        
        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
        faces = face_cascade.detectMultiScale(gray, 1.1, 5)

        if len(faces) == 0:
            st.error("Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t n√†o trong ·∫£nh!")
            return None, None

        # L·∫•y m·∫∑t l·ªõn nh·∫•t
        (x, y, w, h) = max(faces, key=lambda f: f[2] * f[3])

        # 3. T√≠nh to√°n Crop theo t·ª∑ l·ªá
        # Quy chu·∫©n: M·∫∑t chi·∫øm kho·∫£ng 70-75% chi·ªÅu cao ·∫£nh
        crop_h = int(h * 2.5) 
        crop_w = int(crop_h * target_ratio) # T√≠nh chi·ªÅu r·ªông d·ª±a tr√™n t·ª∑ l·ªá
        
        face_center_x = x + w // 2
        top_y = int(y - (h * 0.6)) # L·∫•y d∆∞ ph·∫ßn ƒë·∫ßu m·ªôt ch√∫t
        left_x = int(face_center_x - crop_w // 2)

        # T·∫°o canvas
        canvas_layer = Image.new("RGBA", (crop_w, crop_h), (0,0,0,0))
        canvas_layer.paste(no_bg, (-left_x, -top_y), no_bg)

        face_info = {
            "chin_y": (y + h) - top_y, 
            "center_x": crop_w // 2, 
            "face_w": w
        }
        
        return canvas_layer, face_info

    except Exception as e:
        st.error(f"L·ªói x·ª≠ l√Ω: {str(e)}")
        return None, None

def apply_effects(base_img, auto_beautify, smooth, sharp, brightness, color_sat):
    """√Åp d·ª•ng b·ªô l·ªçc l√†m ƒë·∫πp"""
    img_cv = cv2.cvtColor(np.array(base_img), cv2.COLOR_RGBA2BGRA)
    
    # Auto Beauty ƒë∆°n gi·∫£n
    if auto_beautify:
        # TƒÉng s√°ng nh·∫π n·∫øu ·∫£nh t·ªëi
        gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)
        if np.mean(gray) < 120:
            img_cv = cv2.convertScaleAbs(img_cv, alpha=1.2, beta=10)

    # L√†m m·ªãn da (Bilateral Filter)
    if smooth > 0:
        d = 5
        sigma = int(smooth * 2) + 10
        b, g, r, a = cv2.split(img_cv)
        rgb = cv2.merge([b,g,r])
        rgb = cv2.bilateralFilter(rgb, d=d, sigmaColor=sigma, sigmaSpace=sigma)
        img_cv = cv2.merge([rgb, a])

    # TƒÉng ƒë·ªô n√©t
    if sharp > 0:
        b, g, r, a = cv2.split(img_cv)
        rgb = cv2.merge([b,g,r])
        gaussian = cv2.GaussianBlur(rgb, (0, 0), 2.0)
        weight = 1.0 + (sharp / 5.0)
        rgb = cv2.addWeighted(rgb, weight, gaussian, - (weight - 1.0), 0)
        img_cv = cv2.merge([rgb, a])

    img_result = Image.fromarray(cv2.cvtColor(img_cv, cv2.COLOR_BGRA2RGBA))

    # Ch·ªânh m√†u & S√°ng
    if color_sat != 1.0:
        img_result = ImageEnhance.Color(img_result).enhance(color_sat)
    if brightness != 1.0:
        img_result = ImageEnhance.Brightness(img_result).enhance(brightness)
        
    return img_result

# --- 3. GIAO DI·ªÜN CH√çNH (STREAMLIT) ---

col1, col2 = st.columns([1, 2])

with col1:
    st.header("üõ† Thi·∫øt l·∫≠p")
    
    # --- PH·∫¶N 1: QUY ƒê·ªäNH ·∫¢NH ---
    with st.expander("üìã QUY ƒê·ªäNH CH·ª§P ·∫¢NH (ƒê·ªçc k·ªπ)", expanded=True):
        st.markdown("""
        * **Khu√¥n m·∫∑t:** Nh√¨n th·∫≥ng, bi·ªÉu c·∫£m t·ª± nhi√™n.
        * **M·∫Øt & M√¥i:** M·∫Øt m·ªü to, m√≠m m√¥i, kh√¥ng c∆∞·ªùi h·ªü rƒÉng.
        * **T∆∞ th·∫ø:** Kh√¥ng nghi√™ng ƒë·∫ßu, kh√¥ng c√∫i ƒë·∫ßu.
        * **T√≥c:** G·ªçn g√†ng, **kh√¥ng che tr√°n**, kh√¥ng che l√¥ng m√†y.
        * **Tr·∫°ng th√°i:** Kh√¥ng cau m√†y, kh√¥ng b·ª±c t·ª©c.
        """)
    
    # --- PH·∫¶N 2: UPLOAD ---
    uploaded_file = st.file_uploader("1. T·∫£i ·∫£nh ch√¢n dung l√™n", type=['jpg', 'png', 'jpeg'])

    # --- PH·∫¶N 3: T√ôY CH·ªåN K√çCH TH∆Ø·ªöC & M√ÄU N·ªÄN ---
    st.subheader("2. Ch·ªçn quy c√°ch")
    
    # Ch·ªçn k√≠ch th∆∞·ªõc
    size_option = st.radio("K√≠ch th∆∞·ªõc ·∫£nh:", ["4x6 cm (H·ªô chi·∫øu/Qu·ªëc t·∫ø)", "3x4 cm (GPLX/Kh√°m s·ª©c kh·ªèe)"])
    target_ratio = 3/4 if "3x4" in size_option else 4/6
    
    # Ch·ªçn m√†u n·ªÅn
    bg_color_name = st.radio("M√†u n·ªÅn:", ["Tr·∫Øng", "Xanh d∆∞∆°ng"], horizontal=True)
    
    # M√£ m√†u (RGBA)
    if bg_color_name == "Xanh d∆∞∆°ng":
        bg_color_val = (66, 135, 245, 255) # Xanh d∆∞∆°ng chu·∫©n th·∫ª
    else:
        bg_color_val = (255, 255, 255, 255) # Tr·∫Øng

    # --- LOGIC X·ª¨ L√ù L·∫†I KHI ƒê·ªîI K√çCH TH∆Ø·ªöC ---
    if uploaded_file:
        current_state_key = f"{uploaded_file.name}_{size_option}"
        
        if 'last_state_key' not in st.session_state or st.session_state.last_state_key != current_state_key:
            base_img, face_info = process_input_image(uploaded_file, target_ratio)
            if base_img:
                st.session_state.base_img = base_img
                st.session_state.face_info = face_info
                st.session_state.last_state_key = current_state_key

    # --- PH·∫¶N 4: CH·ªàNH ƒê·∫∏P ---
    st.markdown("---")
    st.subheader("3. L√†m ƒë·∫πp")
    auto_check = st.checkbox("‚ú® Auto S√°ng Da", value=True)
    smooth_val = st.slider("M·ªãn da", 0, 30, 0)
    bright_val = st.slider("ƒê·ªô s√°ng", 0.8, 1.3, 1.0, 0.05)

with col2:
    st.header(f"üñº K·∫øt qu·∫£ ({size_option})")
    
    if 'base_img' in st.session_state and st.session_state.base_img:
        current_base = st.session_state.base_img
        info = st.session_state.face_info
        
        # 1. √Åp d·ª•ng hi·ªáu ·ª©ng l√†m ƒë·∫πp
        processed_person = apply_effects(current_base, auto_check, smooth_val, 0, bright_val, 1.0)
        
        # 2. T·∫°o n·ªÅn theo m√†u ƒë√£ ch·ªçn
        w, h = processed_person.size
        final_img = Image.new("RGBA", (w, h), bg_color_val)
        
        # 3. Gh√©p ng∆∞·ªùi l√™n n·ªÅn
        final_img.paste(processed_person, (0, 0), processed_person)
        
        # 4. Hi·ªÉn th·ªã
        final_rgb = final_img.convert("RGB")
        st.image(final_rgb, width=350)
        
        # 5. N√∫t t·∫£i v·ªÅ
        buf = io.BytesIO()
        final_rgb.save(buf, format="JPEG", quality=100, dpi=(300, 300))
        byte_im = buf.getvalue()
        
        file_name_dl = "anh_3x4_xanh.jpg" if "3x4" in size_option else "anh_4x6_trang.jpg"
        
        st.download_button(
            label="üíæ T·∫¢I ·∫¢NH V·ªÄ M√ÅY",
            data=byte_im,
            file_name=file_name_dl,
            mime="image/jpeg"
        )
            
    else:
        st.info("üëà Vui l√≤ng t·∫£i ·∫£nh l√™n v√† ƒë·ªçc k·ªπ quy ƒë·ªãnh b√™n tr√°i.")
