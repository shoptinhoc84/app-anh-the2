import streamlit as st
from PIL import Image, ImageEnhance
import cv2
import numpy as np
from rembg import remove, new_session
import io
import math

# --- 1. C·∫§U H√åNH & CACHE ---
st.set_page_config(page_title="Studio ·∫¢nh Th·∫ª Pro", layout="wide")

@st.cache_resource
def get_rembg_session():
    return new_session("u2netp")

st.title("üì∏ Studio ·∫¢nh Th·∫ª - AI Chuy√™n Nghi·ªáp")
st.markdown("---")

# --- 2. C√ÅC H√ÄM X·ª¨ L√ù ·∫¢NH ---

def rotate_image(image, angle):
    """
    Xoay ·∫£nh theo g√≥c (ƒë·ªô) m√† kh√¥ng l√†m m·∫•t g√≥c ·∫£nh (gi·ªØ nguy√™n alpha)
    """
    image_center = tuple(np.array(image.shape[1::-1]) / 2)
    rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)
    result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)
    return result

def get_face_angle(gray_img, face_rect):
    """
    T√≠nh g√≥c nghi√™ng d·ª±a tr√™n 2 m·∫Øt
    """
    (x, y, w, h) = face_rect
    roi_gray = gray_img[y:y+h, x:x+w]
    
    # T√¨m m·∫Øt
    eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')
    eyes = eye_cascade.detectMultiScale(roi_gray, 1.1, 5)
    
    if len(eyes) >= 2:
        # S·∫Øp x·∫øp m·∫Øt tr√°i/ph·∫£i theo tr·ª•c x
        eyes = sorted(eyes, key=lambda e: e[0])
        (ex1, ey1, ew1, eh1) = eyes[0]
        (ex2, ey2, ew2, eh2) = eyes[-1] # L·∫•y m·∫Øt xa nh·∫•t ƒë·ªÉ tr√°nh nh·∫ßm m≈©i
        
        # T·ªça ƒë·ªô t√¢m m·∫Øt
        p1 = (ex1 + ew1//2, ey1 + eh1//2)
        p2 = (ex2 + ew2//2, ey2 + eh2//2)
        
        # T√≠nh g√≥c
        delta_x = p2[0] - p1[0]
        delta_y = p2[1] - p1[1]
        angle = np.degrees(np.arctan2(delta_y, delta_x))
        return angle
    return 0

def process_input_image(uploaded_file, target_ratio=4/6):
    try:
        image = Image.open(uploaded_file)
        
        # 1. T√°ch n·ªÅn tr∆∞·ªõc
        with st.spinner('ƒêang t√°ch n·ªÅn & c√¢n ch·ªânh...'):
            session = get_rembg_session()
            no_bg_pil = remove(image, session=session)
            
        # Chuy·ªÉn sang OpenCV ƒë·ªÉ x·ª≠ l√Ω
        no_bg = cv2.cvtColor(np.array(no_bg_pil), cv2.COLOR_RGBA2BGRA)
        
        # 2. T√¨m m·∫∑t l·∫ßn 1 (ƒë·ªÉ l·∫•y v√πng t√¨m m·∫Øt)
        # T√°ch k√™nh alpha ƒë·ªÉ t√¨m m·∫∑t tr√™n n·ªÅn ·∫£nh g·ªëc (ch√≠nh x√°c h∆°n) ho·∫∑c convert sang gray
        # ·ªû ƒë√¢y d√πng gray t·ª´ ·∫£nh ƒë√£ t√°ch n·ªÅn c≈©ng ·ªïn
        gray = cv2.cvtColor(no_bg, cv2.COLOR_BGRA2GRAY)
        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
        faces = face_cascade.detectMultiScale(gray, 1.1, 5)

        if len(faces) == 0:
            st.error("Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t!")
            return None, None

        # L·∫•y m·∫∑t l·ªõn nh·∫•t
        face_rect = max(faces, key=lambda f: f[2] * f[3])
        
        # --- 3. T·ª∞ ƒê·ªòNG XOAY TH·∫≤NG M·∫∂T (NEW) ---
        angle = get_face_angle(gray, face_rect)
        
        # Ch·ªâ xoay n·∫øu nghi√™ng ƒë√°ng k·ªÉ (> 1 ƒë·ªô) v√† kh√¥ng qu√° l·ªë (< 45 ƒë·ªô)
        if abs(angle) > 1 and abs(angle) < 45:
            # st.info(f"Ph√°t hi·ªán ƒë·∫ßu nghi√™ng {angle:.1f} ƒë·ªô. ƒêang t·ª± ƒë·ªông xoay th·∫≥ng...") 
            # Xoay ·∫£nh no_bg
            no_bg = rotate_image(no_bg, angle)
            
            # QUAN TR·ªåNG: Ph·∫£i t√¨m l·∫°i m·∫∑t sau khi xoay v√¨ t·ªça ƒë·ªô ƒë√£ ƒë·ªïi
            gray_new = cv2.cvtColor(no_bg, cv2.COLOR_BGRA2GRAY)
            faces_new = face_cascade.detectMultiScale(gray_new, 1.1, 5)
            if len(faces_new) > 0:
                face_rect = max(faces_new, key=lambda f: f[2] * f[3])
        
        (x, y, w, h) = face_rect

        # --- 4. C·∫ÆT ·∫¢NH (GI·ªÆ C·∫§U H√åNH B·∫†N TH√çCH) ---
        if target_ratio < 0.7: 
            # 4x6 (H·ªô chi·∫øu): Zoom 2.0, Offset 0.45
            zoom_factor = 2.0  
            top_offset = 0.45   
        else:
            # 3x4 (Gi·∫•y t·ªù): Zoom 2.2, Offset 0.5
            zoom_factor = 2.2
            top_offset = 0.5

        crop_h = int(h * zoom_factor) 
        crop_w = int(crop_h * target_ratio)
        
        face_center_x = x + w // 2
        top_y = int(y - (h * top_offset)) 
        left_x = int(face_center_x - crop_w // 2)

        # Convert ng∆∞·ª£c l·∫°i PIL ƒë·ªÉ crop an to√†n (x·ª≠ l√Ω tr√†n vi·ªÅn)
        img_final_pil = Image.fromarray(cv2.cvtColor(no_bg, cv2.COLOR_BGRA2RGBA))
        
        # T·∫°o canvas trong su·ªët
        canvas = Image.new("RGBA", (crop_w, crop_h), (0,0,0,0))
        
        # Paste ·∫£nh v√†o canvas (t·ª± ƒë·ªông x·ª≠ l√Ω ph·∫ßn √¢m)
        canvas.paste(img_final_pil, (-left_x, -top_y), img_final_pil)

        face_info = {"chin_y": (y + h) - top_y, "center_x": crop_w // 2}
        
        return canvas, face_info

    except Exception as e:
        st.error(f"L·ªói: {str(e)}")
        return None, None

def apply_effects(base_img, auto_beautify, smooth, sharp, brightness):
    img_cv = cv2.cvtColor(np.array(base_img), cv2.COLOR_RGBA2BGRA)
    
    if auto_beautify:
        gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)
        if np.mean(gray) < 120:
            img_cv = cv2.convertScaleAbs(img_cv, alpha=1.2, beta=10)

    if smooth > 0:
        d = 5
        sigma = int(smooth * 2) + 10
        rgb = cv2.cvtColor(img_cv, cv2.COLOR_BGRA2BGR)
        rgb = cv2.bilateralFilter(rgb, d=d, sigmaColor=sigma, sigmaSpace=sigma)
        b,g,r = cv2.split(rgb)
        a = cv2.split(img_cv)[3]
        img_cv = cv2.merge([b,g,r,a])

    if sharp > 0:
        rgb = cv2.cvtColor(img_cv, cv2.COLOR_BGRA2BGR)
        gaussian = cv2.GaussianBlur(rgb, (0, 0), 2.0)
        weight = 1.0 + (sharp / 5.0)
        rgb = cv2.addWeighted(rgb, weight, gaussian, - (weight - 1.0), 0)
        b,g,r = cv2.split(rgb)
        a = cv2.split(img_cv)[3]
        img_cv = cv2.merge([b,g,r,a])

    img_result = Image.fromarray(cv2.cvtColor(img_cv, cv2.COLOR_BGRA2RGBA))
    if brightness != 1.0:
        img_result = ImageEnhance.Brightness(img_result).enhance(brightness)
        
    return img_result

def create_print_layout(img_person, size_type):
    # Kh·ªï 10x15cm (4x6 inch) - 300 DPI
    PAPER_W, PAPER_H = 1748, 1181 
    bg_paper = Image.new("RGB", (PAPER_W, PAPER_H), (255, 255, 255))
    
    if "4x6" in size_type:
        target_w, target_h = 472, 708
        rows, cols = 1, 3
        start_x, start_y = 100, 200
        gap = 50
    else:
        target_w, target_h = 354, 472
        rows, cols = 2, 4
        start_x, start_y = 100, 100
        gap = 40
        
    img_resized = img_person.resize((target_w, target_h), Image.Resampling.LANCZOS)
    
    count = 0
    for r in range(rows):
        for c in range(cols):
            x = start_x + c * (target_w + gap)
            y = start_y + r * (target_h + gap)
            if x + target_w < PAPER_W and y + target_h < PAPER_H:
                bg_paper.paste(img_resized, (x, y))
                count += 1
    return bg_paper, count

# --- 3. GIAO DI·ªÜN CH√çNH ---

col1, col2 = st.columns([1, 2])

with col1:
    st.header("üõ† Thi·∫øt l·∫≠p")
    uploaded_file = st.file_uploader("T·∫£i ·∫£nh l√™n", type=['jpg', 'png', 'jpeg'])

    st.subheader("Quy c√°ch")
    size_option = st.radio("K√≠ch th∆∞·ªõc:", ["4x6 cm (H·ªô chi·∫øu)", "3x4 cm (Gi·∫•y t·ªù)"])
    target_ratio = 3/4 if "3x4" in size_option else 4/6
    
    bg_name = st.radio("M√†u n·ªÅn:", ["Tr·∫Øng", "Xanh Chu·∫©n", "Xanh Nh·∫°t"], horizontal=True)
    bg_map = {
        "Tr·∫Øng": (255, 255, 255, 255),
        "Xanh Chu·∫©n": (66, 135, 245, 255),
        "Xanh Nh·∫°t": (135, 206, 250, 255)
    }
    bg_val = bg_map.get(bg_name, (255,255,255,255))

    if uploaded_file:
        state_key = f"{uploaded_file.name}_{size_option}"
        if 'last_key' not in st.session_state or st.session_state.last_key != state_key:
            base_img, info = process_input_image(uploaded_file, target_ratio)
            if base_img:
                st.session_state.base = base_img
                st.session_state.last_key = state_key

    st.markdown("---")
    st.subheader("L√†m ƒë·∫πp")
    auto_check = st.checkbox("Auto S√°ng Da", value=True)
    smooth_val = st.slider("M·ªãn da", 0, 30, 0)
    bright_val = st.slider("ƒê·ªô s√°ng", 0.8, 1.3, 1.0, 0.05)

with col2:
    st.header(f"üñº K·∫øt qu·∫£ ({size_option})")
    
    if 'base' in st.session_state and st.session_state.base:
        # 1. Hi·ªáu ·ª©ng
        final_person = apply_effects(st.session_state.base, auto_check, smooth_val, 0, bright_val)
        
        # 2. Gh√©p n·ªÅn
        w, h = final_person.size
        final_img = Image.new("RGBA", (w, h), bg_val)
        final_img.paste(final_person, (0, 0), final_person)
        final_rgb = final_img.convert("RGB")
        
        st.image(final_rgb, width=300, caption="·∫¢nh th·∫ª ho√†n thi·ªán")
        
        # 3. Khu v·ª±c t·∫£i v·ªÅ
        st.markdown("---")
        c1, c2 = st.columns(2)
        
        # N√∫t t·∫£i ·∫£nh ƒë∆°n
        buf = io.BytesIO()
        final_rgb.save(buf, format="JPEG", quality=100, dpi=(300, 300))
        with c1:
            st.download_button("‚¨áÔ∏è T·∫£i ·∫£nh ƒë∆°n (File g·ªëc)", buf.getvalue(), f"anh_the_{bg_name}.jpg", "image/jpeg")

        # N√∫t t·∫£i file in
        with c2:
            if st.button("üñ®Ô∏è Xem file in 10x15cm"):
                paper, qty = create_print_layout(final_rgb, size_option)
                st.image(paper, caption=f"Demo in {qty} ·∫£nh", use_container_width=True)
                
                buf_p = io.BytesIO()
                paper.save(buf_p, format="JPEG", quality=100, dpi=(300, 300))
                st.download_button("‚¨áÔ∏è T·∫£i File In (Ra ti·ªám in lu√¥n)", buf_p.getvalue(), "file_in_10x15.jpg", "image/jpeg")
            
    else:
        st.info("üëà T·∫£i ·∫£nh l√™n ƒë·ªÉ b·∫Øt ƒë·∫ßu. H·ªá th·ªëng s·∫Ω t·ª± ƒë·ªông c√¢n b·∫±ng m·∫∑t nghi√™ng.")
