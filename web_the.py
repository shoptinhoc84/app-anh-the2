import streamlit as st
from PIL import Image, ImageEnhance
import cv2
import numpy as np
from rembg import remove, new_session
import io

# --- 1. C·∫§U H√åNH & CACHE ---
st.set_page_config(page_title="Studio ·∫¢nh Th·∫ª Online", layout="wide")

# D√πng model 'u2netp' (nh·∫π) ƒë·ªÉ ch·∫°y m∆∞·ª£t m√†
@st.cache_resource
def get_rembg_session():
    return new_session("u2netp")

st.title("üì∏ Studio ·∫¢nh Th·∫ª - Web Version")
st.markdown("---")

# --- 2. C√ÅC H√ÄM X·ª¨ L√ù ·∫¢NH ---

def process_input_image(uploaded_file, target_ratio=4/6):
    """
    X·ª≠ l√Ω t√°ch n·ªÅn v√† crop m·∫∑t theo t·ª∑ l·ªá
    """
    try:
        image = Image.open(uploaded_file)
        
        # 1. T√°ch n·ªÅn
        with st.spinner('ƒêang x·ª≠ l√Ω ·∫£nh...'):
            session = get_rembg_session()
            no_bg = remove(image, session=session)

        # 2. T√¨m m·∫∑t (OpenCV)
        cv_img = cv2.cvtColor(np.array(no_bg.convert("RGB")), cv2.COLOR_RGB2BGR)
        gray = cv2.cvtColor(cv_img, cv2.COLOR_BGR2GRAY)
        
        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
        faces = face_cascade.detectMultiScale(gray, 1.1, 5)

        if len(faces) == 0:
            st.error("Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t n√†o trong ·∫£nh!")
            return None, None

        # L·∫•y m·∫∑t l·ªõn nh·∫•t
        (x, y, w, h) = max(faces, key=lambda f: f[2] * f[3])

        # 3. T√≠nh to√°n Crop (ƒê√É CH·ªàNH S·ª¨A CHO M·∫∂T TO 78%)
        
        if target_ratio < 0.7: 
            # === C·∫§U H√åNH CHO 4x6 (H·ªò CHI·∫æU) ===
            # Y√™u c·∫ßu: M·∫∑t chi·∫øm ~78% ·∫£nh -> Zoom s√°t h∆°n n·ªØa
            zoom_factor = 1.45  # Gi·∫£m s·ªë n√†y xu·ªëng ƒë·ªÉ m·∫∑t to h∆°n (C≈© l√† 1.6)
            top_offset = 0.20   # ƒê·∫©y khung l√™n cao ƒë·ªÉ kh√¥ng b·ªã m·∫•t ƒë·ªânh ƒë·∫ßu
        else:
            # === C·∫§U H√åNH CHO 3x4 (GI·∫§Y T·ªú) ===
            # Gi·ªØ nguy√™n t·ª∑ l·ªá c√¢n ƒë·ªëi c√≥ vai
            zoom_factor = 2.2
            top_offset = 0.5

        crop_h = int(h * zoom_factor) 
        crop_w = int(crop_h * target_ratio)
        
        face_center_x = x + w // 2
        # T√≠nh to√°n m√©p tr√™n (Top Y)
        top_y = int(y - (h * top_offset)) 
        left_x = int(face_center_x - crop_w // 2)

        # T·∫°o canvas
        canvas_layer = Image.new("RGBA", (crop_w, crop_h), (0,0,0,0))
        canvas_layer.paste(no_bg, (-left_x, -top_y), no_bg)

        face_info = {
            "chin_y": (y + h) - top_y, 
            "center_x": crop_w // 2, 
            "face_w": w
        }
        
        return canvas_layer, face_info

    except Exception as e:
        st.error(f"L·ªói x·ª≠ l√Ω: {str(e)}")
        return None, None

def apply_effects(base_img, auto_beautify, smooth, sharp, brightness, color_sat):
    """√Åp d·ª•ng b·ªô l·ªçc l√†m ƒë·∫πp"""
    img_cv = cv2.cvtColor(np.array(base_img), cv2.COLOR_RGBA2BGRA)
    
    if auto_beautify:
        gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)
        if np.mean(gray) < 120:
            img_cv = cv2.convertScaleAbs(img_cv, alpha=1.2, beta=10)

    if smooth > 0:
        d = 5
        sigma = int(smooth * 2) + 10
        b, g, r, a = cv2.split(img_cv)
        rgb = cv2.merge([b,g,r])
        rgb = cv2.bilateralFilter(rgb, d=d, sigmaColor=sigma, sigmaSpace=sigma)
        img_cv = cv2.merge([rgb, a])

    if sharp > 0:
        b, g, r, a = cv2.split(img_cv)
        rgb = cv2.merge([b,g,r])
        gaussian = cv2.GaussianBlur(rgb, (0, 0), 2.0)
        weight = 1.0 + (sharp / 5.0)
        rgb = cv2.addWeighted(rgb, weight, gaussian, - (weight - 1.0), 0)
        img_cv = cv2.merge([rgb, a])

    img_result = Image.fromarray(cv2.cvtColor(img_cv, cv2.COLOR_BGRA2RGBA))

    if color_sat != 1.0:
        img_result = ImageEnhance.Color(img_result).enhance(color_sat)
    if brightness != 1.0:
        img_result = ImageEnhance.Brightness(img_result).enhance(brightness)
        
    return img_result

# --- 3. GIAO DI·ªÜN CH√çNH (STREAMLIT) ---

col1, col2 = st.columns([1, 2])

with col1:
    st.header("üõ† Thi·∫øt l·∫≠p")
    
    uploaded_file = st.file_uploader("1. T·∫£i ·∫£nh ch√¢n dung l√™n", type=['jpg', 'png', 'jpeg'])

    st.subheader("2. Ch·ªçn quy c√°ch")
    
    # K√≠ch th∆∞·ªõc
    size_option = st.radio("K√≠ch th∆∞·ªõc:", ["4x6 cm (H·ªô chi·∫øu)", "3x4 cm (Gi·∫•y t·ªù)"])
    target_ratio = 3/4 if "3x4" in size_option else 4/6
    
    # M√†u n·ªÅn
    bg_color_name = st.radio("M√†u n·ªÅn:", ["Tr·∫Øng", "Xanh Chu·∫©n", "Xanh Nh·∫°t", "Xanh ƒê·∫≠m"], horizontal=True)
    
    if bg_color_name == "Tr·∫Øng":
        bg_color_val = (255, 255, 255, 255)
    elif bg_color_name == "Xanh Chu·∫©n":
        bg_color_val = (66, 135, 245, 255)
    elif bg_color_name == "Xanh Nh·∫°t":
        bg_color_val = (135, 206, 250, 255)
    elif bg_color_name == "Xanh ƒê·∫≠m":
        bg_color_val = (0, 71, 171, 255)

    # --- LOGIC X·ª¨ L√ù L·∫†I ---
    if uploaded_file:
        current_state_key = f"{uploaded_file.name}_{size_option}"
        
        if 'last_state_key' not in st.session_state or st.session_state.last_state_key != current_state_key:
            base_img, face_info = process_input_image(uploaded_file, target_ratio)
            if base_img:
                st.session_state.base_img = base_img
                st.session_state.face_info = face_info
                st.session_state.last_state_key = current_state_key

    st.markdown("---")
    st.subheader("3. L√†m ƒë·∫πp")
    auto_check = st.checkbox("‚ú® Auto S√°ng Da", value=True)
    smooth_val = st.slider("M·ªãn da", 0, 30, 0)
    bright_val = st.slider("ƒê·ªô s√°ng", 0.8, 1.3, 1.0, 0.05)

with col2:
    st.header(f"üñº K·∫øt qu·∫£ ({size_option})")
    
    if 'base_img' in st.session_state and st.session_state.base_img:
        current_base = st.session_state.base_img
        
        # 1. √Åp d·ª•ng hi·ªáu ·ª©ng
        processed_person = apply_effects(current_base, auto_check, smooth_val, 0, bright_val, 1.0)
        
        # 2. T·∫°o n·ªÅn
        w, h = processed_person.size
        final_img = Image.new("RGBA", (w, h), bg_color_val)
        
        # 3. Gh√©p
        final_img.paste(processed_person, (0, 0), processed_person)
        
        # 4. Hi·ªÉn th·ªã
        final_rgb = final_img.convert("RGB")
        st.image(final_rgb, width=350)
        
        # 5. T·∫£i v·ªÅ
        buf = io.BytesIO()
        final_rgb.save(buf, format="JPEG", quality=100, dpi=(300, 300))
        byte_im = buf.getvalue()
        
        file_name_dl = f"anh_the_{bg_color_name}.jpg"
        
        st.download_button(
            label="üíæ T·∫¢I ·∫¢NH V·ªÄ M√ÅY",
            data=byte_im,
            file_name=file_name_dl,
            mime="image/jpeg"
        )
            
    else:
        st.info("üëà Vui l√≤ng t·∫£i ·∫£nh l√™n ·ªü c·ªôt b√™n tr√°i.")

