import streamlit as st
from PIL import Image, ImageEnhance
import cv2
import numpy as np
from rembg import remove, new_session
import io

# --- 1. Cáº¤U HÃŒNH & CACHE ---
st.set_page_config(page_title="Studio áº¢nh Tháº» V2.1 Fix", layout="wide")

@st.cache_resource
def get_rembg_session():
    return new_session("u2netp")

st.title("ðŸ“¸ Studio áº¢nh Tháº» - Pro Max (Super Sharp Edition)")
st.markdown("---")

# --- 2. HÃ€M RESET ---
def reset_beauty_params():
    """ÄÆ°a toÃ n bá»™ thÃ´ng sá»‘ vá» máº·c Ä‘á»‹nh"""
    st.session_state.val_smooth = 0
    st.session_state.val_makeup = 0
    st.session_state.val_exposure = 1.0
    st.session_state.val_contrast = 1.0
    st.session_state.val_temp = 0
    st.session_state.val_sharp_amount = 0 
    st.session_state.val_denoise = 0      
    st.session_state.val_blacks = 0       
    st.session_state.val_whites = 0       
    st.session_state.val_dehaze = 0
    st.session_state.ai_enabled = False

# --- 3. CÃC HÃ€M Xá»¬ LÃ áº¢NH Cá»T LÃ•I (CORE) ---

def rotate_image(image, angle):
    (h, w) = image.shape[:2]
    center = (w // 2, h // 2)
    M = cv2.getRotationMatrix2D(center, angle, 1.0)
    rotated = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_LANCZOS4, borderMode=cv2.BORDER_REPLICATE)
    return rotated

def get_face_angle(gray_img, face_rect):
    (x, y, w, h) = face_rect
    roi_gray = gray_img[y:y+h, x:x+w]
    eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')
    eyes = eye_cascade.detectMultiScale(roi_gray, 1.1, 5)
    
    if len(eyes) >= 2:
        eyes = sorted(eyes, key=lambda e: e[0])
        (ex1, ey1, ew1, eh1) = eyes[0]
        (ex2, ey2, ew2, eh2) = eyes[-1]
        
        p1 = (ex1 + ew1//2, ey1 + eh1//2)
        p2 = (ex2 + ew2//2, ey2 + eh2//2)
        
        delta_x = p2[0] - p1[0]
        delta_y = p2[1] - p1[1]
        
        if delta_x < w/5: return 0.0
        angle = np.degrees(np.arctan2(delta_y, delta_x))
        return angle
    return 0.0

def process_raw_to_nobg(file_input):
    image = Image.open(file_input)
    session = get_rembg_session()
    no_bg_pil = remove(image, session=session, alpha_matting=True)
    no_bg_cv = cv2.cvtColor(np.array(no_bg_pil), cv2.COLOR_RGBA2BGRA)
    return no_bg_cv

def crop_final_image(no_bg_img, manual_angle, target_ratio):
    try:
        img_working = no_bg_img.copy()
        gray = cv2.cvtColor(img_working, cv2.COLOR_BGRA2GRAY)
        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
        faces = face_cascade.detectMultiScale(gray, 1.1, 5)

        if len(faces) == 0:
            return None, "KhÃ´ng tÃ¬m tháº¥y khuÃ´n máº·t", 0

        face_rect = max(faces, key=lambda f: f[2] * f[3])
        auto_angle = get_face_angle(gray, face_rect)
        
        if abs(auto_angle) < 1.0: auto_angle = 0.0
        if abs(auto_angle) > 20.0: auto_angle = 0.0 

        total_angle = auto_angle + manual_angle
        
        if abs(total_angle) > 0.1:
            img_rotated = rotate_image(img_working, total_angle)
        else:
            img_rotated = img_working

        gray_new = cv2.cvtColor(img_rotated, cv2.COLOR_BGRA2GRAY)
        faces_new = face_cascade.detectMultiScale(gray_new, 1.1, 5)
        
        if len(faces_new) > 0:
            (x, y, w, h) = max(faces_new, key=lambda f: f[2] * f[3])
        else:
            (x, y, w, h) = face_rect

        if target_ratio < 0.7: 
            zoom_factor = 2.0  
            top_offset = 0.45   
        else:
            zoom_factor = 2.2
            top_offset = 0.5

        crop_h = int(h * zoom_factor) 
        crop_w = int(crop_h * target_ratio)
        
        face_center_x = x + w // 2
        top_y = int(y - (h * top_offset)) 
        left_x = int(face_center_x - crop_w // 2)

        img_pil = Image.fromarray(cv2.cvtColor(img_rotated, cv2.COLOR_BGRA2RGBA))
        canvas = Image.new("RGBA", (crop_w, crop_h), (0,0,0,0))
        canvas.paste(img_pil, (-left_x, -top_y), img_pil)

        return canvas, f"GÃ³c Auto: {auto_angle:.1f}Â° | Tá»•ng: {total_angle:.1f}Â°", total_angle

    except Exception as e:
        return None, str(e), 0

# --- 4. Bá»˜ Lá»ŒC NÃ‚NG CAO (FIXED SHARPEN) ---

def adjust_levels(image, blacks=0, whites=0):
    if blacks == 0 and whites == 0: return image
    in_black = blacks
    in_white = 255 - whites
    in_black = max(0, min(in_black, 100))
    in_white = max(150, min(in_white, 255))
    
    lut = np.zeros(256, dtype=np.uint8)
    for i in range(256):
        val = (i - in_black) * 255 / (in_white - in_black)
        lut[i] = np.clip(val, 0, 255)
        
    b, g, r, a = cv2.split(image)
    b = cv2.LUT(b, lut)
    g = cv2.LUT(g, lut)
    r = cv2.LUT(r, lut)
    return cv2.merge([b, g, r, a])

def apply_super_sharpen(image, amount=0):
    """
    HÃ m lÃ m nÃ©t má»›i: Sá»­ dá»¥ng ma tráº­n tÃ­ch cháº­p (Convolution Kernel)
    GiÃºp áº£nh nÃ©t Ä‘anh vÃ  rÃµ rÃ ng hÆ¡n Unsharp Mask cÅ©.
    """
    if amount == 0: return image
    
    # Kernel lÃ m nÃ©t cÆ¡ báº£n
    kernel = np.array([[0, -1, 0],
                       [-1, 5, -1],
                       [0, -1, 0]])
    
    # Ãp dá»¥ng bá»™ lá»c
    sharpened = cv2.filter2D(image, -1, kernel)
    
    # Trá»™n áº£nh gá»‘c vÃ  áº£nh nÃ©t theo thanh trÆ°á»£t (0-50)
    # Chia cho 40 Ä‘á»ƒ alpha cÃ³ thá»ƒ lÃªn tá»›i > 1.0 (Ráº¥t nÃ©t) náº¿u kÃ©o max
    alpha = amount / 40.0 
    
    output = cv2.addWeighted(image, 1.0 - alpha, sharpened, alpha, 0)
    return output

def apply_denoise(image, strength=0):
    if strength == 0: return image
    b, g, r, a = cv2.split(image)
    rgb = cv2.merge([b, g, r])
    h_val = strength
    denoised_rgb = cv2.fastNlMeansDenoisingColored(rgb, None, h_val, h_val, 7, 21)
    b, g, r = cv2.split(denoised_rgb)
    return cv2.merge([b, g, r, a])

def apply_advanced_effects(base_img, params):
    img_cv = cv2.cvtColor(np.array(base_img), cv2.COLOR_RGBA2BGRA)
    
    # 1. Giáº£m nhiá»…u (Denoise)
    if params['denoise'] > 0:
        img_cv = apply_denoise(img_cv, params['denoise'])

    # 2. Má»‹n da
    if params['smooth'] > 0:
        d = 5
        sigma = int(params['smooth'] * 2) + 10
        rgb = cv2.cvtColor(img_cv, cv2.COLOR_BGRA2BGR)
        rgb = cv2.bilateralFilter(rgb, d=d, sigmaColor=sigma, sigmaSpace=sigma)
        b,g,r = cv2.split(rgb)
        a = cv2.split(img_cv)[3]
        img_cv = cv2.merge([b,g,r,a])

    # 3. Dehaze
    if params['dehaze'] > 0:
        b, g, r, a = cv2.split(img_cv)
        lab = cv2.cvtColor(cv2.merge([b,g,r]), cv2.COLOR_BGR2LAB)
        l, aa, bb = cv2.split(lab)
        clahe = cv2.createCLAHE(clipLimit=1.0 + (params['dehaze']/10.0), tileGridSize=(8,8))
        cl = clahe.apply(l)
        limg = cv2.merge((cl,aa,bb))
        final = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)
        b, g, r = cv2.split(final)
        img_cv = cv2.merge([b, g, r, a])
        
    # 4. Nhiá»‡t Ä‘á»™ mÃ u
    if params['temp'] != 0:
        temp = int(params['temp'])
        b, g, r, a = cv2.split(img_cv)
        if temp > 0:
            r = cv2.add(r, temp)
            b = cv2.subtract(b, temp)
        else:
            r = cv2.add(r, temp)
            b = cv2.subtract(b, temp)
        img_cv = cv2.merge([b, g, r, a])

    # 5. Há»“ng hÃ o
    if params['makeup'] > 0:
        b, g, r, a = cv2.split(img_cv)
        hsv = cv2.cvtColor(cv2.merge([b,g,r]), cv2.COLOR_BGR2HSV)
        h, s, v = cv2.split(hsv)
        s = cv2.add(s, int(params['makeup'] * 1.5))
        v = cv2.add(v, int(params['makeup'] * 0.5))
        final_hsv = cv2.merge([h, s, v])
        final_bgr = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)
        fb, fg, fr = cv2.split(final_bgr)
        img_cv = cv2.merge([fb, fg, fr, a])

    # 6. Levels
    if params['blacks'] > 0 or params['whites'] > 0:
        img_cv = adjust_levels(img_cv, params['blacks'], params['whites'])
    
    # 7. SUPER SHARPEN (ÄÃ£ fix)
    if params['sharp_amount'] > 0:
        img_cv = apply_super_sharpen(img_cv, params['sharp_amount'])

    img_pil = Image.fromarray(cv2.cvtColor(img_cv, cv2.COLOR_BGRA2RGBA))
    
    if params['exposure'] != 1.0:
        img_pil = ImageEnhance.Brightness(img_pil).enhance(params['exposure'])
    if params['contrast'] != 1.0:
        img_pil = ImageEnhance.Contrast(img_pil).enhance(params['contrast'])

    return img_pil

def create_print_layout(img_person, size_type):
    PAPER_W, PAPER_H = 1748, 1181 
    bg_paper = Image.new("RGB", (PAPER_W, PAPER_H), (255, 255, 255))
    
    if "4x6" in size_type:
        target_w, target_h = 472, 708
        rows, cols = 1, 3
        start_x, start_y = 100, 200
        gap = 50
    else:
        target_w, target_h = 354, 472
        rows, cols = 2, 4
        start_x, start_y = 100, 100
        gap = 40
        
    img_resized = img_person.resize((target_w, target_h), Image.Resampling.LANCZOS)
    count = 0
    for r in range(rows):
        for c in range(cols):
            x = start_x + c * (target_w + gap)
            y = start_y + r * (target_h + gap)
            if x + target_w < PAPER_W and y + target_h < PAPER_H:
                bg_paper.paste(img_resized, (x, y))
                count += 1
    return bg_paper, count

# --- 5. GIAO DIá»†N CHÃNH ---

col1, col2 = st.columns([1, 2.2])

with col1:
    st.header("ðŸ›  Thiáº¿t láº­p")
    
    input_method = st.radio("Nguá»“n áº£nh:", ["ðŸ“ Táº£i áº£nh lÃªn", "ðŸ“· Chá»¥p áº£nh"], horizontal=True)
    input_file = None
    if input_method == "ðŸ“ Táº£i áº£nh lÃªn":
        input_file = st.file_uploader("Chá»n áº£nh tá»« mÃ¡y", type=['jpg', 'png', 'jpeg'])
    else:
        input_file = st.camera_input("Chá»¥p áº£nh ngay")

    st.subheader("2. Cáº¯t & Xoay")
    size_option = st.radio("KÃ­ch thÆ°á»›c:", ["4x6 cm (Há»™ chiáº¿u)", "3x4 cm (Giáº¥y tá»)"])
    target_ratio = 3/4 if "3x4" in size_option else 4/6
    
    manual_rot = st.slider("Chá»‰nh nghiÃªng Ä‘áº§u:", -15.0, 15.0, 0.0, 0.5)
    
    bg_name = st.radio("MÃ u ná»n:", ["Tráº¯ng", "Xanh Chuáº©n", "Xanh Nháº¡t"], horizontal=True)
    bg_map = {"Tráº¯ng": (255, 255, 255, 255), "Xanh Chuáº©n": (66, 135, 245, 255), "Xanh Nháº¡t": (135, 206, 250, 255)}
    bg_val = bg_map.get(bg_name)

    if input_file:
        current_file_key = f"{input_file.name}_{input_file.size}"
        if 'current_file_key' not in st.session_state or st.session_state.current_file_key != current_file_key:
            with st.spinner('Äang tÃ¡ch ná»n & nháº­n diá»‡n...'):
                st.session_state.raw_nobg = process_raw_to_nobg(input_file)
                st.session_state.current_file_key = current_file_key
        
        if 'raw_nobg' in st.session_state:
            final_crop, debug_info, _ = crop_final_image(st.session_state.raw_nobg, manual_rot, target_ratio)
            if final_crop:
                st.session_state.base = final_crop
                st.caption(f"â„¹ï¸ {debug_info}")
            else:
                st.error(f"Lá»—i: {debug_info}")

    st.markdown("---")
    
    c_head, c_btn = st.columns([3, 2])
    with c_head:
        st.subheader("3. Xá»­ lÃ½ áº£nh")
    with c_btn:
        st.button("ðŸ”„ Reset", on_click=reset_beauty_params)

    with st.expander("ðŸ¤– AI Style (Tá»± Ä‘á»™ng)", expanded=False):
        ai_enabled = st.checkbox("Báº­t cháº¿ Ä‘á»™ AI Preset", key='ai_enabled')
        if ai_enabled:
            gender_style = st.radio("Phong cÃ¡ch:", ["Nam", "Ná»¯"])
            if gender_style == "Nam":
                st.session_state.val_smooth = 5
                st.session_state.val_makeup = 2
                st.session_state.val_exposure = 1.05
                st.session_state.val_contrast = 1.15
                st.session_state.val_sharp_amount = 20 # NÃ©t cao
                st.session_state.val_denoise = 5
                st.session_state.val_blacks = 10
                st.session_state.val_whites = 5
            else:
                st.session_state.val_smooth = 25
                st.session_state.val_makeup = 20
                st.session_state.val_exposure = 1.1
                st.session_state.val_contrast = 1.05
                st.session_state.val_sharp_amount = 10
                st.session_state.val_denoise = 10
                st.session_state.val_whites = 15

    # --- SLIDER THá»¦ CÃ”NG ---
    with st.expander("âœ¨ CÃ´ng cá»¥ chá»‰nh sá»­a", expanded=True):
        st.markdown("**1. Chi tiáº¿t & XÃ³a má»**")
        # Slider Ä‘á»™ nÃ©t tÄƒng range lÃªn 50 Ä‘á»ƒ dá»… chá»‰nh
        p_sharp_amount = st.slider("Äá»™ sáº¯c nÃ©t (Super Sharp)", 0, 50, st.session_state.get('val_sharp_amount', 0), key="val_sharp_amount", help="KÃ©o lÃªn Ä‘á»ƒ tháº¥y áº£nh nÃ©t Ä‘anh láº¡i")
        p_dehaze = st.slider("XÃ³a lá»›p phá»§ má»", 0, 30, st.session_state.get('val_dehaze', 0), key="val_dehaze")
        p_denoise = st.slider("Giáº£m nhiá»…u háº¡t", 0, 20, st.session_state.get('val_denoise', 0), key="val_denoise")

        st.markdown("**2. Ãnh sÃ¡ng & MÃ u sáº¯c**")
        col_b, col_w = st.columns(2)
        with col_b:
            p_blacks = st.slider("NÃ¢ng mÃ u Äen", 0, 50, st.session_state.get('val_blacks', 0), key="val_blacks")
        with col_w:
            p_whites = st.slider("NÃ¢ng mÃ u Tráº¯ng", 0, 50, st.session_state.get('val_whites', 0), key="val_whites")
            
        p_exposure = st.slider("Äá»™ sÃ¡ng tá»•ng", 0.5, 1.5, st.session_state.get('val_exposure', 1.0), 0.05, key="val_exposure")
        p_contrast = st.slider("TÆ°Æ¡ng pháº£n", 0.5, 1.5, st.session_state.get('val_contrast', 1.0), 0.05, key="val_contrast")
        
        st.markdown("**3. Da & Trang Ä‘iá»ƒm**")
        p_smooth = st.slider("Má»‹n da", 0, 30, st.session_state.get('val_smooth', 0), key="val_smooth")
        p_makeup = st.slider("Há»“ng hÃ o", 0, 50, st.session_state.get('val_makeup', 0), key="val_makeup")
        p_temp = st.slider("Nhiá»‡t Ä‘á»™ mÃ u", -50, 50, st.session_state.get('val_temp', 0), key="val_temp")

    params = {
        'smooth': p_smooth, 'makeup': p_makeup,
        'exposure': p_exposure, 'contrast': p_contrast, 'temp': p_temp,
        'sharp_amount': p_sharp_amount, 'dehaze': p_dehaze,
        'blacks': p_blacks, 'whites': p_whites, 'denoise': p_denoise
    }

with col2:
    st.header(f"ðŸ–¼ Káº¿t quáº£ ({size_option})")
    
    if 'base' in st.session_state and st.session_state.base:
        with st.spinner("Äang Ã¡p dá»¥ng hiá»‡u á»©ng..."):
            final_person = apply_advanced_effects(st.session_state.base, params)
        
        w, h = final_person.size
        final_img = Image.new("RGBA", (w, h), bg_val)
        final_img.paste(final_person, (0, 0), final_person)
        final_rgb = final_img.convert("RGB")
        
        st.image(final_rgb, width=350, caption="áº¢nh hoÃ n thiá»‡n")
        
        st.markdown("---")
        c1, c2 = st.columns(2)
        
        buf = io.BytesIO()
        final_rgb.save(buf, format="JPEG", quality=100, dpi=(300, 300))
        
        name_mapping = {"Tráº¯ng": "white", "Xanh Chuáº©n": "blue_standard", "Xanh Nháº¡t": "blue_light"}
        safe_bg_name = name_mapping.get(bg_name, "custom")
        
        c1.download_button(
            label="â¬‡ï¸ Táº£i áº£nh JPEG", 
            data=buf.getvalue(), 
            file_name=f"anh_the_{safe_bg_name}.jpg", 
            mime="image/jpeg"
        )

        if c2.button("ðŸ–¨ï¸ In ghÃ©p khá»• A6"):
            paper, qty = create_print_layout(final_rgb, size_option)
            st.image(paper, caption=f"Layout in: {qty} áº£nh", use_container_width=True)
            buf_p = io.BytesIO()
            paper.save(buf_p, format="JPEG", quality=100, dpi=(300, 300))
            st.download_button("â¬‡ï¸ Táº£i file in", buf_p.getvalue(), "layout_in_A6.jpg", "image/jpeg", key='dl_print')
            
    else:
        st.info("ðŸ‘ˆ HÃ£y chá»n áº£nh á»Ÿ cá»™t bÃªn trÃ¡i Ä‘á»ƒ báº¯t Ä‘áº§u xá»­ lÃ½.")
